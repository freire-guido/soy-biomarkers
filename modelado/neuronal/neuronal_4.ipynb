{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from sklearn import model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bioproject</th>\n",
       "      <th>tejido</th>\n",
       "      <th>estres</th>\n",
       "      <th>tratamiento</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biosample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SAMD00235524</th>\n",
       "      <td>PRJDB10183</td>\n",
       "      <td>seedling</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMD00235525</th>\n",
       "      <td>PRJDB10183</td>\n",
       "      <td>seedling</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMD00235526</th>\n",
       "      <td>PRJDB10183</td>\n",
       "      <td>seedling</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMD00235527</th>\n",
       "      <td>PRJDB10183</td>\n",
       "      <td>seedling</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMD00235528</th>\n",
       "      <td>PRJDB10183</td>\n",
       "      <td>seedling</td>\n",
       "      <td>control</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMN36760719</th>\n",
       "      <td>PRJNA999924</td>\n",
       "      <td>seed</td>\n",
       "      <td>cold</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMN36760720</th>\n",
       "      <td>PRJNA999924</td>\n",
       "      <td>seed</td>\n",
       "      <td>cold</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMN36760721</th>\n",
       "      <td>PRJNA999924</td>\n",
       "      <td>seed</td>\n",
       "      <td>cold</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMN36760722</th>\n",
       "      <td>PRJNA999924</td>\n",
       "      <td>seed</td>\n",
       "      <td>cold</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMN36760723</th>\n",
       "      <td>PRJNA999924</td>\n",
       "      <td>seed</td>\n",
       "      <td>cold</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8754 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               bioproject    tejido   estres tratamiento\n",
       "biosample                                               \n",
       "SAMD00235524   PRJDB10183  seedling  control     control\n",
       "SAMD00235525   PRJDB10183  seedling  control     control\n",
       "SAMD00235526   PRJDB10183  seedling  control     control\n",
       "SAMD00235527   PRJDB10183  seedling  control     control\n",
       "SAMD00235528   PRJDB10183  seedling  control     control\n",
       "...                   ...       ...      ...         ...\n",
       "SAMN36760719  PRJNA999924      seed     cold   treatment\n",
       "SAMN36760720  PRJNA999924      seed     cold   treatment\n",
       "SAMN36760721  PRJNA999924      seed     cold   treatment\n",
       "SAMN36760722  PRJNA999924      seed     cold   treatment\n",
       "SAMN36760723  PRJNA999924      seed     cold   treatment\n",
       "\n",
       "[8754 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "venancio = pd.read_parquet('../../expresion/venancio.parquet')\n",
    "\n",
    "annot = pd.read_csv('../../anotacion/gemini_annot.csv', index_col=0)\n",
    "annot = annot[annot['tejido'].notna() & annot['estres'].notna()]\n",
    "annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "venancio, annot = venancio.align(annot, join='inner', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "consamples = annot['bioproject'].map(annot['bioproject'].value_counts() > 2)\n",
    "convarianza = venancio.var() > 0.01\n",
    "\n",
    "filtrado = venancio.loc[consamples, convarianza]\n",
    "X, y = filtrado.align(annot, join='inner', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toda esta pipeline de preprocesamiento la pasaria a tf.data para escalarla en vez de sklearn pero es mas comodo implementarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[\"estres\"]\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X,\n",
    "    y_encoded,\n",
    "    test_size=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes neuronales representan una aproximación fundamentalmente diferente al problema de expresión diferencial. Para nuestro análisis, implementamos una arquitectura feed-forward simple con dos capas ocultas, utilizando activación ReLU y dropout (0.3) para prevenir el sobreajuste e incentivar la exploración de genes. La capa de entrada tiene dimensión $p$ (número total de genes) y la de salida utiliza activación softmax para la clasificación multiclase.\n",
    "\n",
    "Para manejar la alta dimensionalidad (característica de los datos de expresión génica), se intenta añadir una capa de reducción de dimensionalidad antes de la clasificación. Esto comprime las variables de entrada en un espacio latente de menor dimensionalidad. \n",
    "\n",
    "El entrenamiento se realizó utilizando el optimizador Adam con una tasa de aprendizaje inicial de 1e-4 y programación de tasa de aprendizaje cíclica para evitar mínimos locales. Para abordar el desbalance de clases, implementamos ponderación de clases inversamente proporcional a su frecuencia en los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/godo/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-01-26 14:30:53.462344: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,646,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">495</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m6,646,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m495\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,657,615</span> (25.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,657,615\u001b[0m (25.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,657,615</span> (25.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,657,615\u001b[0m (25.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# el dropout es bastante importante por la dimensionalidad del dataset, sino te overfitea bastante\n",
    "model = models.Sequential([\n",
    "    layers.Dense(128, activation=\"relu\", input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(len(np.unique(y_train)), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# uso la tasa inicial default en lugar de 1e-4, no cambia mucho\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tasa de aprendizaje ciclica\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch % 10 == 0 and epoch != 0: # este 10% conviene tunearlo\n",
    "        lr = lr * 0.9 \n",
    "    return lr \n",
    "\n",
    "lr_callback = callbacks.LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 14:31:41.504763: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 510546264 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.2589 - loss: 9.3675"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 14:31:52.903704: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 127740420 exceeds 10% of free system memory.\n",
      "2025-01-26 14:31:54.075264: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 53173248 exceeds 10% of free system memory.\n",
      "2025-01-26 14:31:54.113678: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 53173248 exceeds 10% of free system memory.\n",
      "2025-01-26 14:31:54.149749: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 53173248 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 282ms/step - accuracy: 0.2612 - loss: 9.3274 - val_accuracy: 0.5593 - val_loss: 2.0629 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.4660 - loss: 4.0899 - val_accuracy: 0.5772 - val_loss: 1.7380 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.4808 - loss: 3.1441 - val_accuracy: 0.5854 - val_loss: 1.3931 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.5182 - loss: 2.1930 - val_accuracy: 0.6309 - val_loss: 1.2386 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.5234 - loss: 1.9058 - val_accuracy: 0.6228 - val_loss: 1.1628 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.5664 - loss: 1.6962 - val_accuracy: 0.6748 - val_loss: 1.1278 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.5531 - loss: 1.6362 - val_accuracy: 0.6537 - val_loss: 1.1175 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - accuracy: 0.6030 - loss: 1.4053 - val_accuracy: 0.6959 - val_loss: 1.0376 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.6182 - loss: 1.2500 - val_accuracy: 0.6943 - val_loss: 0.9350 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6670 - loss: 1.0824 - val_accuracy: 0.6959 - val_loss: 0.9619 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.6442 - loss: 1.1907 - val_accuracy: 0.6764 - val_loss: 0.9539 - learning_rate: 9.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.6486 - loss: 1.1453 - val_accuracy: 0.7073 - val_loss: 0.8935 - learning_rate: 9.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - accuracy: 0.6835 - loss: 1.0124 - val_accuracy: 0.6959 - val_loss: 0.8627 - learning_rate: 9.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.6821 - loss: 1.0250 - val_accuracy: 0.7220 - val_loss: 0.8561 - learning_rate: 9.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.7008 - loss: 0.9749 - val_accuracy: 0.7171 - val_loss: 0.7803 - learning_rate: 9.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - accuracy: 0.7194 - loss: 0.9157 - val_accuracy: 0.7447 - val_loss: 0.8073 - learning_rate: 9.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 143ms/step - accuracy: 0.7058 - loss: 1.0286 - val_accuracy: 0.7577 - val_loss: 0.8176 - learning_rate: 9.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.7071 - loss: 0.9378 - val_accuracy: 0.7382 - val_loss: 0.7904 - learning_rate: 9.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 476ms/step - accuracy: 0.7111 - loss: 0.9016 - val_accuracy: 0.7659 - val_loss: 0.7683 - learning_rate: 9.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 391ms/step - accuracy: 0.7387 - loss: 0.8334 - val_accuracy: 0.7821 - val_loss: 0.7180 - learning_rate: 9.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.7347 - loss: 0.7468 - val_accuracy: 0.7463 - val_loss: 0.7688 - learning_rate: 8.1000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.7698 - loss: 0.6688 - val_accuracy: 0.7724 - val_loss: 0.7264 - learning_rate: 8.1000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.7735 - loss: 0.6485 - val_accuracy: 0.7886 - val_loss: 0.7078 - learning_rate: 8.1000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 467ms/step - accuracy: 0.7642 - loss: 0.6787 - val_accuracy: 0.7772 - val_loss: 0.7249 - learning_rate: 8.1000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 530ms/step - accuracy: 0.7694 - loss: 0.6719 - val_accuracy: 0.7642 - val_loss: 0.7159 - learning_rate: 8.1000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 300ms/step - accuracy: 0.7924 - loss: 0.6514 - val_accuracy: 0.7935 - val_loss: 0.7162 - learning_rate: 8.1000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 639ms/step - accuracy: 0.7724 - loss: 0.6215 - val_accuracy: 0.7610 - val_loss: 0.6956 - learning_rate: 8.1000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 450ms/step - accuracy: 0.7900 - loss: 0.5879 - val_accuracy: 0.7659 - val_loss: 0.7382 - learning_rate: 8.1000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 567ms/step - accuracy: 0.7837 - loss: 0.6347 - val_accuracy: 0.7691 - val_loss: 0.6978 - learning_rate: 8.1000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 415ms/step - accuracy: 0.7914 - loss: 0.6004 - val_accuracy: 0.7545 - val_loss: 0.7262 - learning_rate: 8.1000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 470ms/step - accuracy: 0.7809 - loss: 0.5908 - val_accuracy: 0.7659 - val_loss: 0.7596 - learning_rate: 7.2900e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 577ms/step - accuracy: 0.8008 - loss: 0.6072 - val_accuracy: 0.7659 - val_loss: 0.7373 - learning_rate: 7.2900e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - accuracy: 0.8114 - loss: 0.5311 - val_accuracy: 0.7967 - val_loss: 0.6684 - learning_rate: 7.2900e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.8195 - loss: 0.5202 - val_accuracy: 0.7675 - val_loss: 0.7129 - learning_rate: 7.2900e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.8187 - loss: 0.5187 - val_accuracy: 0.8033 - val_loss: 0.7151 - learning_rate: 7.2900e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 529ms/step - accuracy: 0.8134 - loss: 0.5607 - val_accuracy: 0.7870 - val_loss: 0.7459 - learning_rate: 7.2900e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 427ms/step - accuracy: 0.8114 - loss: 0.5286 - val_accuracy: 0.7935 - val_loss: 0.7376 - learning_rate: 7.2900e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 610ms/step - accuracy: 0.8180 - loss: 0.5527 - val_accuracy: 0.7837 - val_loss: 0.7415 - learning_rate: 7.2900e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 578ms/step - accuracy: 0.8305 - loss: 0.5229 - val_accuracy: 0.7740 - val_loss: 0.6974 - learning_rate: 7.2900e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 466ms/step - accuracy: 0.8153 - loss: 0.5070 - val_accuracy: 0.7935 - val_loss: 0.6365 - learning_rate: 7.2900e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 532ms/step - accuracy: 0.8283 - loss: 0.4715 - val_accuracy: 0.8000 - val_loss: 0.6834 - learning_rate: 6.5610e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 460ms/step - accuracy: 0.8448 - loss: 0.4499 - val_accuracy: 0.7984 - val_loss: 0.6835 - learning_rate: 6.5610e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 524ms/step - accuracy: 0.8385 - loss: 0.4887 - val_accuracy: 0.8130 - val_loss: 0.6783 - learning_rate: 6.5610e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 740ms/step - accuracy: 0.8408 - loss: 0.4665 - val_accuracy: 0.7854 - val_loss: 0.7164 - learning_rate: 6.5610e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.8474 - loss: 0.4515 - val_accuracy: 0.7854 - val_loss: 0.7232 - learning_rate: 6.5610e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.8689 - loss: 0.3986 - val_accuracy: 0.7951 - val_loss: 0.7116 - learning_rate: 6.5610e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 482ms/step - accuracy: 0.8469 - loss: 0.4161 - val_accuracy: 0.8033 - val_loss: 0.7364 - learning_rate: 6.5610e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 424ms/step - accuracy: 0.8450 - loss: 0.4338 - val_accuracy: 0.8179 - val_loss: 0.6979 - learning_rate: 6.5610e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 520ms/step - accuracy: 0.8558 - loss: 0.4156 - val_accuracy: 0.8081 - val_loss: 0.7230 - learning_rate: 6.5610e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 387ms/step - accuracy: 0.8541 - loss: 0.4141 - val_accuracy: 0.8228 - val_loss: 0.6860 - learning_rate: 6.5610e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 411ms/step - accuracy: 0.8547 - loss: 0.3979 - val_accuracy: 0.8000 - val_loss: 0.6537 - learning_rate: 5.9049e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 558ms/step - accuracy: 0.8780 - loss: 0.3543 - val_accuracy: 0.7919 - val_loss: 0.6532 - learning_rate: 5.9049e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 446ms/step - accuracy: 0.8785 - loss: 0.3488 - val_accuracy: 0.7967 - val_loss: 0.7267 - learning_rate: 5.9049e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 490ms/step - accuracy: 0.8569 - loss: 0.4144 - val_accuracy: 0.8179 - val_loss: 0.7283 - learning_rate: 5.9049e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 545ms/step - accuracy: 0.8629 - loss: 0.3702 - val_accuracy: 0.8179 - val_loss: 0.7115 - learning_rate: 5.9049e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 144ms/step - accuracy: 0.8680 - loss: 0.3730 - val_accuracy: 0.8146 - val_loss: 0.7523 - learning_rate: 5.9049e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 94ms/step - accuracy: 0.8728 - loss: 0.3413 - val_accuracy: 0.8211 - val_loss: 0.7075 - learning_rate: 5.9049e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 323ms/step - accuracy: 0.8899 - loss: 0.3358 - val_accuracy: 0.8195 - val_loss: 0.7318 - learning_rate: 5.9049e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 472ms/step - accuracy: 0.8723 - loss: 0.3757 - val_accuracy: 0.8163 - val_loss: 0.6710 - learning_rate: 5.9049e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 561ms/step - accuracy: 0.8684 - loss: 0.3501 - val_accuracy: 0.8179 - val_loss: 0.7506 - learning_rate: 5.9049e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 507ms/step - accuracy: 0.9018 - loss: 0.2993 - val_accuracy: 0.8114 - val_loss: 0.8043 - learning_rate: 5.3144e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 723ms/step - accuracy: 0.8851 - loss: 0.3124 - val_accuracy: 0.8211 - val_loss: 0.7375 - learning_rate: 5.3144e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 454ms/step - accuracy: 0.8985 - loss: 0.3039 - val_accuracy: 0.8341 - val_loss: 0.6969 - learning_rate: 5.3144e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 475ms/step - accuracy: 0.8950 - loss: 0.3115 - val_accuracy: 0.8195 - val_loss: 0.7888 - learning_rate: 5.3144e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 622ms/step - accuracy: 0.8947 - loss: 0.2914 - val_accuracy: 0.8228 - val_loss: 0.7585 - learning_rate: 5.3144e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 595ms/step - accuracy: 0.9137 - loss: 0.2401 - val_accuracy: 0.8195 - val_loss: 0.7792 - learning_rate: 5.3144e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 451ms/step - accuracy: 0.9046 - loss: 0.2816 - val_accuracy: 0.8228 - val_loss: 0.8050 - learning_rate: 5.3144e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - accuracy: 0.9126 - loss: 0.2633 - val_accuracy: 0.8260 - val_loss: 0.7406 - learning_rate: 5.3144e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.9032 - loss: 0.2823 - val_accuracy: 0.8260 - val_loss: 0.7554 - learning_rate: 5.3144e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 158ms/step - accuracy: 0.9024 - loss: 0.3127 - val_accuracy: 0.8211 - val_loss: 0.7628 - learning_rate: 5.3144e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 462ms/step - accuracy: 0.9111 - loss: 0.2873 - val_accuracy: 0.8163 - val_loss: 0.8012 - learning_rate: 4.7830e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 339ms/step - accuracy: 0.9186 - loss: 0.2648 - val_accuracy: 0.8179 - val_loss: 0.7650 - learning_rate: 4.7830e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 587ms/step - accuracy: 0.9155 - loss: 0.2688 - val_accuracy: 0.8211 - val_loss: 0.7738 - learning_rate: 4.7830e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 567ms/step - accuracy: 0.9237 - loss: 0.2281 - val_accuracy: 0.8276 - val_loss: 0.7346 - learning_rate: 4.7830e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 448ms/step - accuracy: 0.9265 - loss: 0.2047 - val_accuracy: 0.8163 - val_loss: 0.8028 - learning_rate: 4.7830e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 791ms/step - accuracy: 0.9218 - loss: 0.2352 - val_accuracy: 0.8146 - val_loss: 0.8303 - learning_rate: 4.7830e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 363ms/step - accuracy: 0.9142 - loss: 0.2297 - val_accuracy: 0.8293 - val_loss: 0.8728 - learning_rate: 4.7830e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 750ms/step - accuracy: 0.9211 - loss: 0.2416 - val_accuracy: 0.8276 - val_loss: 0.8011 - learning_rate: 4.7830e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 439ms/step - accuracy: 0.9104 - loss: 0.2574 - val_accuracy: 0.8276 - val_loss: 0.8026 - learning_rate: 4.7830e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 178ms/step - accuracy: 0.9326 - loss: 0.2136 - val_accuracy: 0.8179 - val_loss: 0.8280 - learning_rate: 4.7830e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.9202 - loss: 0.2414 - val_accuracy: 0.8325 - val_loss: 0.7693 - learning_rate: 4.3047e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 492ms/step - accuracy: 0.9335 - loss: 0.1988 - val_accuracy: 0.8244 - val_loss: 0.8622 - learning_rate: 4.3047e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 550ms/step - accuracy: 0.9293 - loss: 0.1892 - val_accuracy: 0.8260 - val_loss: 0.8225 - learning_rate: 4.3047e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 530ms/step - accuracy: 0.9333 - loss: 0.1949 - val_accuracy: 0.8276 - val_loss: 0.8383 - learning_rate: 4.3047e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 470ms/step - accuracy: 0.9334 - loss: 0.2013 - val_accuracy: 0.8325 - val_loss: 0.8129 - learning_rate: 4.3047e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 480ms/step - accuracy: 0.9338 - loss: 0.2123 - val_accuracy: 0.8211 - val_loss: 0.8358 - learning_rate: 4.3047e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 566ms/step - accuracy: 0.9370 - loss: 0.2013 - val_accuracy: 0.8228 - val_loss: 0.9154 - learning_rate: 4.3047e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 766ms/step - accuracy: 0.9324 - loss: 0.1970 - val_accuracy: 0.8260 - val_loss: 0.9246 - learning_rate: 4.3047e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 484ms/step - accuracy: 0.9383 - loss: 0.1700 - val_accuracy: 0.8244 - val_loss: 0.9071 - learning_rate: 4.3047e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 782ms/step - accuracy: 0.9287 - loss: 0.2112 - val_accuracy: 0.8179 - val_loss: 0.9103 - learning_rate: 4.3047e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 565ms/step - accuracy: 0.9323 - loss: 0.1934 - val_accuracy: 0.8211 - val_loss: 0.9600 - learning_rate: 3.8742e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 174ms/step - accuracy: 0.9394 - loss: 0.1844 - val_accuracy: 0.8179 - val_loss: 0.9003 - learning_rate: 3.8742e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.9342 - loss: 0.1947 - val_accuracy: 0.8341 - val_loss: 0.9759 - learning_rate: 3.8742e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 250ms/step - accuracy: 0.9394 - loss: 0.2001 - val_accuracy: 0.8244 - val_loss: 0.9339 - learning_rate: 3.8742e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 459ms/step - accuracy: 0.9450 - loss: 0.2088 - val_accuracy: 0.8276 - val_loss: 0.9274 - learning_rate: 3.8742e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 480ms/step - accuracy: 0.9474 - loss: 0.1641 - val_accuracy: 0.8244 - val_loss: 0.9240 - learning_rate: 3.8742e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 488ms/step - accuracy: 0.9352 - loss: 0.2196 - val_accuracy: 0.8260 - val_loss: 0.9313 - learning_rate: 3.8742e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 643ms/step - accuracy: 0.9390 - loss: 0.2090 - val_accuracy: 0.8260 - val_loss: 0.9388 - learning_rate: 3.8742e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 379ms/step - accuracy: 0.9532 - loss: 0.1513 - val_accuracy: 0.8293 - val_loss: 0.9339 - learning_rate: 3.8742e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 671ms/step - accuracy: 0.9454 - loss: 0.1438 - val_accuracy: 0.8211 - val_loss: 0.9718 - learning_rate: 3.8742e-04\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[lr_callback, tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8302 - loss: 1.0443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.119916319847107, 0.8179453611373901]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
